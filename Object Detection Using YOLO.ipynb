{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eae163d-5838-489d-963c-4a46a71b00ff",
   "metadata": {},
   "source": [
    "### Object Detection Using YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcb54d18-976a-4e6c-b12b-80fb1168a9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load Yolo\n",
    "\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")  \n",
    "\n",
    "# dnn is deep neural network\n",
    "\n",
    "classes = []   \n",
    "\n",
    "# in classes you can specify objects that you want to detect \n",
    "\n",
    "# classes=['car','person','bicycle'] \n",
    "\n",
    "with open(\"coco.names\", \"r\") as f:      \n",
    "\n",
    "    classes = [line.strip() for line in f.readlines()]  \n",
    "print(classes)\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a974f2a3-4a2e-40ed-87a1-3437a8e336bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layers: ['yolo_82', 'yolo_94', 'yolo_106']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO model\n",
    "net = cv2.dnn.readNetFromDarknet(\"yolov3.cfg\", \"yolov3.weights\")\n",
    "\n",
    "# Get the names of all layers in the network\n",
    "layer_names = net.getLayerNames()\n",
    "\n",
    "# Get the output layer names\n",
    "unconnected_out_layers = net.getUnconnectedOutLayers()\n",
    "\n",
    "# Check if the output is a 2D array or a 1D array/scalar\n",
    "if len(unconnected_out_layers.shape) == 2:\n",
    "    output_layers = [layer_names[i[0] - 1] for i in unconnected_out_layers]\n",
    "else:\n",
    "    output_layers = [layer_names[i - 1] for i in unconnected_out_layers]\n",
    "\n",
    "# Generate random colors for each class\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "print(\"Output layers:\", output_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d6922e4d-7fc2-48ed-8d37-12c5e1c33f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"image1.jpg\")   \n",
    "\n",
    "# Enter your image name here that you want to detect\n",
    "\n",
    "img = cv2.resize(img, None, fx=0.4, fy=0.4) #OPTIONAL\n",
    "\n",
    "# Resizing the image. None refers to no fixed size. fx and fy are width and height .\n",
    "\n",
    "height, width, channels = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2d1821d5-794f-4738-8769-cb8da3cfa83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)  \n",
    "\n",
    "# True refers to converting into rgb format since opencv uses bgr.\n",
    "\n",
    "net.setInput(blob)  \n",
    "\n",
    "# Passing blob image to yolo algo in network\n",
    "\n",
    "outs = net.forward(output_layers)  \n",
    "\n",
    "# Giving network to output layer for final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9c87257c-1804-4721-b89e-e4f3d79fad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing informations on the screen\n",
    "\n",
    "class_ids = []\n",
    "\n",
    "confidences = []\n",
    "\n",
    "boxes = []\n",
    "\n",
    "for out in outs:\n",
    "\n",
    "    for detection in out:\n",
    "\n",
    "        scores = detection[5:]\n",
    "\n",
    "        class_id = np.argmax(scores)\n",
    "\n",
    "        confidence = scores[class_id]\n",
    "\n",
    "        if confidence > 0.5:\n",
    "\n",
    "            # Object detected\n",
    "\n",
    "            center_x = int(detection[0] * width)\n",
    "\n",
    "            center_y = int(detection[1] * height)\n",
    "\n",
    "            w = int(detection[2] * width)\n",
    "\n",
    "            h = int(detection[3] * height)\n",
    "\n",
    "            # Rectangle coordinates\n",
    "\n",
    "            x = int(center_x - w / 2)\n",
    "\n",
    "            y = int(center_y - h / 2)\n",
    "\n",
    "            boxes.append([x, y, w, h])\n",
    "\n",
    "            confidences.append(float(confidence))\n",
    "\n",
    "            class_ids.append(class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b7b53cca-3a8f-45b5-9987-efcba6102502",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4) \n",
    "\n",
    "# NMS - non max supression\n",
    "\n",
    "#print(indexes)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "for i in range(len(boxes)):\n",
    "\n",
    "    if i in indexes:\n",
    "\n",
    "        x, y, w, h = boxes[i]\n",
    "\n",
    "        label = str(classes[class_ids[i]])\n",
    "\n",
    "        color = colors[i]\n",
    "\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2) \n",
    "\n",
    "        # Draw rectangle around boxes. '2' is the width of box.\n",
    "\n",
    "        cv2.putText(img, label, (x, y + 30), font, 3, color, 3)\n",
    "\n",
    "        # Text in Box to label the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b5e9b215-6168-4ec7-9f55-ccec21683e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\", img) \n",
    "\n",
    "cv2.waitKey(0) \n",
    "\n",
    " # waitkey stops the output\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631fc6a3-aa38-4e33-8984-c5fc3808ca68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db07aac8-3c04-4506-b261-45f734597ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
